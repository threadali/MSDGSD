{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: igraph in c:\\users\\rank arrow\\appdata\\roaming\\python\\python39\\site-packages (0.9.11)\n",
      "Requirement already satisfied: texttable>=1.6.2 in c:\\users\\rank arrow\\appdata\\roaming\\python\\python39\\site-packages (from igraph) (1.6.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4LWUCFVV0oU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys,igraph\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy.io\n",
    "import csv,time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbEC84iwuDmP"
   },
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-nuACdKuBa_"
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as spl\n",
    "import scipy.sparse as sps\n",
    "import scipy.sparse.linalg as spsl\n",
    "\n",
    "\n",
    "def check_1d(inp):\n",
    "    \"\"\"\n",
    "    Check input to be a vector. Converts lists to np.ndarray.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inp : obj\n",
    "        Input vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray or None\n",
    "        Input vector or None\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> check_1d([0, 1, 2, 3])\n",
    "    [0, 1, 2, 3]\n",
    "\n",
    "    >>> check_1d('test')\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(inp, list):\n",
    "        return check_1d(np.array(inp))\n",
    "    if isinstance(inp, np.ndarray):\n",
    "        if inp.ndim == 1: # input is a vector\n",
    "            return inp\n",
    "\n",
    "\n",
    "def check_2d(inp):\n",
    "    \"\"\"\n",
    "    Check input to be a matrix. Converts lists of lists to np.ndarray.\n",
    "\n",
    "    Also allows the input to be a scipy sparse matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inp : obj\n",
    "        Input matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray, scipy.sparse or None\n",
    "        Input matrix or None\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> check_2d([[0, 1], [2, 3]])\n",
    "    [[0, 1], [2, 3]]\n",
    "\n",
    "    >>> check_2d('test')\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(inp, list):\n",
    "        return check_2d(np.array(inp))\n",
    "    if isinstance(inp, (np.ndarray, np.matrixlib.defmatrix.matrix)):\n",
    "        if inp.ndim == 2: # input is a dense matrix\n",
    "            return inp\n",
    "    if sps.issparse(inp):\n",
    "        if inp.ndim == 2: # input is a sparse matrix\n",
    "            return inp\n",
    "\n",
    "\n",
    "def graph_to_laplacian(G, normalized=True):\n",
    "    \"\"\"\n",
    "    Converts a graph from popular Python packages to Laplacian representation.\n",
    "\n",
    "    Currently support NetworkX, graph_tool and igraph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : obj\n",
    "        Input graph\n",
    "    normalized : bool\n",
    "        Whether to use normalized Laplacian.\n",
    "        Normalized and unnormalized Laplacians capture different properties of graphs, e.g. normalized Laplacian spectrum can determine whether a graph is bipartite, but not the number of its edges. We recommend using normalized Laplacian.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scipy.sparse\n",
    "        Laplacian matrix of the input graph\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> graph_to_laplacian(nx.complete_graph(3), 'unnormalized').todense()\n",
    "    [[ 2, -1, -1], [-1,  2, -1], [-1, -1,  2]]\n",
    "\n",
    "    >>> graph_to_laplacian('test')\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "        if isinstance(G, nx.Graph):\n",
    "            if normalized:\n",
    "                return nx.normalized_laplacian_matrix(G)\n",
    "            else:\n",
    "                return nx.laplacian_matrix(G)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import graph_tool.all as gt\n",
    "        if isinstance(G, gt.Graph):\n",
    "            if normalized:\n",
    "                return gt.laplacian_type(G, normalized=True)\n",
    "            else:\n",
    "                return gt.laplacian(G)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import igraph as ig\n",
    "        if isinstance(G, ig.Graph):\n",
    "            if normalized:\n",
    "                return np.array(G.laplacian(normalized=True))\n",
    "            else:\n",
    "                return np.array(G.laplacian())\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def mat_to_laplacian(mat, normalized):\n",
    "    \"\"\"\n",
    "    Converts a sparse or dence adjacency matrix to Laplacian.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : obj\n",
    "        Input adjacency matrix. If it is a Laplacian matrix already, return it.\n",
    "    normalized : bool\n",
    "        Whether to use normalized Laplacian.\n",
    "        Normalized and unnormalized Laplacians capture different properties of graphs, e.g. normalized Laplacian spectrum can determine whether a graph is bipartite, but not the number of its edges. We recommend using normalized Laplacian.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj\n",
    "        Laplacian of the input adjacency matrix\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> mat_to_laplacian(numpy.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]]), False)\n",
    "    [[ 2, -1, -1], [-1,  2, -1], [-1, -1,  2]]\n",
    "\n",
    "    \"\"\"\n",
    "    if sps.issparse(mat):\n",
    "        if np.all(mat.diagonal()>=0): # Check diagonal\n",
    "            if np.all((mat-sps.diags(mat.diagonal())).data <= 0): # Check off-diagonal elements\n",
    "                return mat\n",
    "    else:\n",
    "        if np.all(np.diag(mat)>=0): # Check diagonal\n",
    "            if np.all(mat - np.diag(mat) <= 0): # Check off-diagonal elements\n",
    "                return mat\n",
    "    deg = np.squeeze(np.asarray(mat.sum(axis=1)))\n",
    "    if sps.issparse(mat):\n",
    "        L = sps.diags(deg) - mat\n",
    "    else:\n",
    "        L = np.diag(deg) - mat\n",
    "    if not normalized:\n",
    "        return L\n",
    "    with np.errstate(divide='ignore'):\n",
    "        sqrt_deg = 1.0 / np.sqrt(deg)\n",
    "    sqrt_deg[sqrt_deg==np.inf] = 0\n",
    "    if sps.issparse(mat):\n",
    "        sqrt_deg_mat = sps.diags(sqrt_deg)\n",
    "    else:\n",
    "        sqrt_deg_mat = np.diag(sqrt_deg)\n",
    "    return sqrt_deg_mat.dot(L).dot(sqrt_deg_mat)\n",
    "\n",
    "\n",
    "def updown_linear_approx(eigvals_lower, eigvals_upper, nv):\n",
    "    \"\"\"\n",
    "    Approximates Laplacian spectrum using upper and lower parts of the eigenspectrum.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eigvals_lower : numpy.ndarray\n",
    "        Lower part of the spectrum, sorted\n",
    "    eigvals_upper : numpy.ndarray\n",
    "        Upper part of the spectrum, sorted\n",
    "    nv : int\n",
    "        Total number of nodes (eigenvalues) in the graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Vector of approximated eigenvalues\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> updown_linear_approx([1, 2, 3], [7, 8, 9], 9)\n",
    "    array([1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
    "\n",
    "    \"\"\"\n",
    "    nal = len(eigvals_lower)\n",
    "    nau = len(eigvals_upper)\n",
    "    if nv < nal + nau:\n",
    "        raise ValueError('Number of supplied eigenvalues ({0} lower and {1} upper) is higher than number of nodes ({2})!'.format(nal, nau, nv))\n",
    "    ret = np.zeros(nv)\n",
    "    ret[:nal] = eigvals_lower\n",
    "    ret[-nau:] = eigvals_upper\n",
    "    ret[nal-1:-nau+1] = np.linspace(eigvals_lower[-1], eigvals_upper[0], nv-nal-nau+2)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def eigenvalues_auto(mat, n_eivals='auto'):\n",
    "    \"\"\"\n",
    "    Automatically computes the spectrum of a given Laplacian matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : numpy.ndarray or scipy.sparse\n",
    "        Laplacian matrix\n",
    "    n_eivals : string or int or tuple\n",
    "        Number of eigenvalues to compute / use for approximation.\n",
    "        If string, we expect either 'full' or 'auto', otherwise error will be raised. 'auto' lets the program decide based on the faithful usage. 'full' computes all eigenvalues.\n",
    "        If int, compute n_eivals eigenvalues from each side and approximate using linear growth approximation.\n",
    "        If tuple, we expect two ints, first for lower part of approximation, and second for the upper part.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Vector of approximated eigenvalues\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> eigenvalues_auto(numpy.array([[ 2, -1, -1], [-1,  2, -1], [-1, -1,  2]]), 'auto')\n",
    "    array([0, 3, 3])\n",
    "\n",
    "    \"\"\"\n",
    "    do_full = True\n",
    "    n_lower = 150\n",
    "    n_upper = 150\n",
    "    nv = mat.shape[0]\n",
    "    if n_eivals == 'auto':\n",
    "        if mat.shape[0] > 1024:\n",
    "            do_full = False\n",
    "    if n_eivals == 'full':\n",
    "        do_full = True\n",
    "    if isinstance(n_eivals, int):\n",
    "        n_lower = n_upper = n_eivals\n",
    "        do_full = False\n",
    "    if isinstance(n_eivals, tuple):\n",
    "        n_lower, n_upper = n_eivals\n",
    "        do_full = False\n",
    "    if do_full and sps.issparse(mat):\n",
    "        mat = mat.todense()\n",
    "    if sps.issparse(mat):\n",
    "        if n_lower == n_upper:\n",
    "            tr_eivals = spsl.eigsh(mat, 2*n_lower, which='BE', return_eigenvectors=False)\n",
    "            return updown_linear_approx(tr_eivals[:n_upper], tr_eivals[n_upper:], nv)\n",
    "        else:\n",
    "            lo_eivals = spsl.eigsh(mat, n_lower, which='SM', return_eigenvectors=False)[::-1]\n",
    "            up_eivals = spsl.eigsh(mat, n_upper, which='LM', return_eigenvectors=False)\n",
    "            return updown_linear_approx(lo_eivals, up_eivals, nv)\n",
    "    else:\n",
    "        if do_full:\n",
    "            return spl.eigvalsh(mat)\n",
    "        else:\n",
    "            lo_eivals = spl.eigvalsh(mat, eigvals=(0, n_lower-1))\n",
    "            up_eivals = spl.eigvalsh(mat, eigvals=(nv-n_upper-1, nv-1))\n",
    "            return updown_linear_approx(lo_eivals, up_eivals, nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMnwvXZnuZwl"
   },
   "source": [
    "# kernels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FuOF7PIud9M"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare(descriptor1, descriptor2):\n",
    "    \"\"\"\n",
    "    Computes the distance between two NetLSD representations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    descriptor1: numpy.ndarray\n",
    "        First signature to compare\n",
    "    descriptor2: numpy.ndarray\n",
    "        Second signature to compare\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        NetLSD distance\n",
    "\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(descriptor1-descriptor2)\n",
    "\n",
    "\n",
    "def netlsd(inp, timescales=np.logspace(-2, 2, 250), kernel='heat', eigenvalues='auto', normalization='empty', normalized_laplacian=True):\n",
    "    \"\"\"\n",
    "    Computes NetLSD signature from some given input, timescales, and normalization.\n",
    "\n",
    "    Accepts matrices, common Python graph libraries' graphs, or vectors of eigenvalues. \n",
    "    For precise definition, please refer to \"NetLSD: Hearing the Shape of a Graph\" by A. Tsitsulin, D. Mottin, P. Karras, A. Bronstein, E. Müller. Published at KDD'18.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inp: obj\n",
    "        2D numpy/scipy matrix, common Python graph libraries' graph, or vector of eigenvalues\n",
    "    timescales : numpy.ndarray\n",
    "        Vector of discrete timesteps for the kernel computation\n",
    "    kernel : str\n",
    "        Either 'heat' or 'wave'. Type of a kernel to use for computation.\n",
    "    eigenvalues : str\n",
    "        Either string or int or tuple\n",
    "        Number of eigenvalues to compute / use for approximation.\n",
    "        If string, we expect either 'full' or 'auto', otherwise error will be raised. 'auto' lets the program decide based on the faithful usage. 'full' computes all eigenvalues.\n",
    "        If int, compute n_eivals eigenvalues from each side and approximate using linear growth approximation.\n",
    "        If tuple, we expect two ints, first for lower part of approximation, and second for the upper part.\n",
    "    normalization : str or numpy.ndarray\n",
    "        Either 'empty', 'complete' or None.\n",
    "        If None or any ther value, return unnormalized heat kernel trace.\n",
    "        For the details how 'empty' and 'complete' are computed, please refer to the paper.\n",
    "        If np.ndarray, they are treated as exact normalization constants\n",
    "    normalized_laplacian: bool\n",
    "        Defines whether the eigenvalues came from the normalized Laplacian. It only affects 'complete' normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        NetLSD signature\n",
    "\n",
    "    \"\"\"\n",
    "    if kernel not in {'heat', 'wave'}:\n",
    "        raise AttributeError('Unirecognized kernel type: expected one of [\\'heat\\', \\'wave\\'], got {0}'.format(kernel))\n",
    "    if not isinstance(normalized_laplacian, bool):\n",
    "        raise AttributeError('Unknown Laplacian type: expected bool, got {0}'.format(normalized_laplacian))\n",
    "    if not isinstance(eigenvalues, (int, tuple, str)):\n",
    "        raise AttributeError('Unirecognized requested eigenvalue number: expected type of [\\'str\\', \\'tuple\\', or \\'int\\'], got {0}'.format(type(eigenvalues)))\n",
    "    if not isinstance(timescales, np.ndarray):\n",
    "        raise AttributeError('Unirecognized timescales data type: expected np.ndarray, got {0}'.format(type(timescales)))\n",
    "    if timescales.ndim != 1:\n",
    "        raise AttributeError('Unirecognized timescales dimensionality: expected a vector, got {0}-d array'.format(timescales.ndim))\n",
    "    if normalization not in {'complete', 'empty', 'none', True, False, None}:\n",
    "        if not isinstance(normalization, np.ndarray):\n",
    "            raise AttributeError('Unirecognized normalization type: expected one of [\\'complete\\', \\'empty\\', None or np.ndarray], got {0}'.format(normalization))\n",
    "        if normalization.ndim != 1:\n",
    "            raise AttributeError('Unirecognized normalization dimensionality: expected a vector, got {0}-d array'.format(normalization.ndim))\n",
    "        if timescales.shape[0] != normalization.shape[0]:\n",
    "            raise AttributeError('Unirecognized normalization dimensionality: expected {0}-length vector, got length {1}'.format(timescales.shape[0], normalization.shape[0]))\n",
    "\n",
    "    eivals = check_1d(inp)\n",
    "    if eivals is None:\n",
    "        mat = check_2d(inp)\n",
    "        if mat is None:\n",
    "            mat = graph_to_laplacian(inp, normalized_laplacian)\n",
    "            if mat is None:\n",
    "                raise ValueError('Unirecognized input type: expected one of [\\'np.ndarray\\', \\'scipy.sparse\\', \\'networkx.Graph\\',\\' graph_tool.Graph,\\' or \\'igraph.Graph\\'], got {0}'.format(type(inp)))\n",
    "        else:\n",
    "            mat = mat_to_laplacian(inp, normalized_laplacian)\n",
    "        eivals = eigenvalues_auto(mat, eigenvalues)\n",
    "    if kernel == 'heat':\n",
    "        return _hkt(eivals, timescales, normalization, normalized_laplacian)\n",
    "    else:\n",
    "        return _wkt(eivals, timescales, normalization, normalized_laplacian)\n",
    "\n",
    "\n",
    "def heat(inp,scale, eigenvalues='auto', normalization='empty', normalized_laplacian=True):\n",
    "    \"\"\"\n",
    "    Computes heat kernel trace from some given input, timescales, and normalization.\n",
    "\n",
    "    Accepts matrices, common Python graph libraries' graphs, or vectors of eigenvalues. \n",
    "    For precise definition, please refer to \"NetLSD: Hearing the Shape of a Graph\" by A. Tsitsulin, D. Mottin, P. Karras, A. Bronstein, E. Müller. Published at KDD'18.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inp: obj\n",
    "        2D numpy/scipy matrix, common Python graph libraries' graph, or vector of eigenvalues\n",
    "    timescales : numpy.ndarray\n",
    "        Vector of discrete timesteps for the kernel computation\n",
    "    eigenvalues : str\n",
    "        Either string or int or tuple\n",
    "        Number of eigenvalues to compute / use for approximation.\n",
    "        If string, we expect either 'full' or 'auto', otherwise error will be raised. 'auto' lets the program decide based on the faithful usage. 'full' computes all eigenvalues.\n",
    "        If int, compute n_eivals eigenvalues from each side and approximate using linear growth approximation.\n",
    "        If tuple, we expect two ints, first for lower part of approximation, and second for the upper part.\n",
    "    normalization : str or numpy.ndarray\n",
    "        Either 'empty', 'complete' or None.\n",
    "        If None or any ther value, return unnormalized heat kernel trace.\n",
    "        For the details how 'empty' and 'complete' are computed, please refer to the paper.\n",
    "        If np.ndarray, they are treated as exact normalization constants\n",
    "    normalized_laplacian: bool\n",
    "        Defines whether the eigenvalues came from the normalized Laplacian. It only affects 'complete' normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Heat kernel trace signature\n",
    "\n",
    "    \"\"\"\n",
    "    timescales = np.logspace(-2, 2, scale)\n",
    "    return netlsd(inp, timescales, 'heat', eigenvalues, normalization, normalized_laplacian)\n",
    "\n",
    "\n",
    "def wave(inp, scale, eigenvalues='auto', normalization='empty', normalized_laplacian=True):\n",
    "    \"\"\"\n",
    "    Computes wave kernel trace from some given input, timescales, and normalization.\n",
    "\n",
    "    Accepts matrices, common Python graph libraries' graphs, or vectors of eigenvalues. \n",
    "    For precise definition, please refer to \"NetLSD: Hearing the Shape of a Graph\" by A. Tsitsulin, D. Mottin, P. Karras, A. Bronstein, E. Müller. Published at KDD'18.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inp: obj\n",
    "        2D numpy/scipy matrix, common Python graph libraries' graph, or vector of eigenvalues\n",
    "    timescales : numpy.ndarray\n",
    "        Vector of discrete timesteps for the kernel computation\n",
    "    eigenvalues : str\n",
    "        Either string or int or tuple\n",
    "        Number of eigenvalues to compute / use for approximation.\n",
    "        If string, we expect either 'full' or 'auto', otherwise error will be raised. 'auto' lets the program decide based on the faithful usage. 'full' computes all eigenvalues.\n",
    "        If int, compute n_eivals eigenvalues from each side and approximate using linear growth approximation.\n",
    "        If tuple, we expect two ints, first for lower part of approximation, and second for the upper part.\n",
    "    normalization : str or numpy.ndarray\n",
    "        Either 'empty', 'complete' or None.\n",
    "        If None or any ther value, return unnormalized wave kernel trace.\n",
    "        For the details how 'empty' and 'complete' are computed, please refer to the paper.\n",
    "        If np.ndarray, they are treated as exact normalization constants\n",
    "    normalized_laplacian: bool\n",
    "        Defines whether the eigenvalues came from the normalized Laplacian. It only affects 'complete' normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Wave kernel trace signature\n",
    "\n",
    "    \"\"\"\n",
    "    timescales = np.linspace(0, 2 * np.pi, scale)\n",
    "    return netlsd(inp, timescales, 'wave', eigenvalues, normalization, normalized_laplacian)\n",
    "\n",
    "\n",
    "def _hkt(eivals, timescales, normalization, normalized_laplacian):\n",
    "    \"\"\"\n",
    "    Computes heat kernel trace from given eigenvalues, timescales, and normalization.\n",
    "\n",
    "    For precise definition, please refer to \"NetLSD: Hearing the Shape of a Graph\" by A. Tsitsulin, D. Mottin, P. Karras, A. Bronstein, E. Müller. Published at KDD'18.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eivals : numpy.ndarray\n",
    "        Eigenvalue vector\n",
    "    timescales : numpy.ndarray\n",
    "        Vector of discrete timesteps for the kernel computation\n",
    "    normalization : str or numpy.ndarray\n",
    "        Either 'empty', 'complete' or None.\n",
    "        If None or any ther value, return unnormalized heat kernel trace.\n",
    "        For the details how 'empty' and 'complete' are computed, please refer to the paper.\n",
    "        If np.ndarray, they are treated as exact normalization constants\n",
    "    normalized_laplacian: bool\n",
    "        Defines whether the eigenvalues came from the normalized Laplacian. It only affects 'complete' normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Heat kernel trace signature\n",
    "\n",
    "    \"\"\"\n",
    "    nv = eivals.shape[0]\n",
    "    hkt = np.zeros(timescales.shape)\n",
    "    for idx, t in enumerate(timescales):\n",
    "        # print(\"idx {} and t {} : \".format(idx, t))\n",
    "        hkt[idx] = np.sum(np.exp(-t * eivals))\n",
    "    if isinstance(normalization, np.ndarray):\n",
    "        return hkt / normalization\n",
    "    if normalization == 'empty' or normalization == True:\n",
    "        return hkt / nv\n",
    "    if normalization == 'complete':\n",
    "        if normalized_laplacian:\n",
    "            return hkt / (1 + (nv - 1) * np.exp(-timescales))\n",
    "        else:\n",
    "            return hkt / (1 + nv * np.exp(-nv * timescales))\n",
    "    return hkt\n",
    "\n",
    "\n",
    "def _wkt(eivals, timescales, normalization, normalized_laplacian):\n",
    "    \"\"\"\n",
    "    Computes wave kernel trace from given eigenvalues, timescales, and normalization.\n",
    "\n",
    "    For precise definition, please refer to \"NetLSD: Hearing the Shape of a Graph\" by A. Tsitsulin, D. Mottin, P. Karras, A. Bronstein, E. Müller. Published at KDD'18.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eivals : numpy.ndarray\n",
    "        Eigenvalue vector\n",
    "    timescales : numpy.ndarray\n",
    "        Vector of discrete timesteps for the kernel computation\n",
    "    normalization : str or numpy.ndarray\n",
    "        Either 'empty', 'complete' or None.\n",
    "        If None or any ther value, return unnormalized wave kernel trace.\n",
    "        For the details how 'empty' and 'complete' are computed, please refer to the paper.\n",
    "        If np.ndarray, they are treated as exact normalization constants\n",
    "    normalized_laplacian: bool\n",
    "        Defines whether the eigenvalues came from the normalized Laplacian. It only affects 'complete' normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Wave kernel trace signature\n",
    "\n",
    "    \"\"\"\n",
    "    nv = eivals.shape[0]\n",
    "    wkt = np.zeros(timescales.shape)\n",
    "    for idx, t in enumerate(timescales):\n",
    "        wkt[idx] = np.sum(np.exp(-1j * t * eivals))\n",
    "    if isinstance(normalization, np.ndarray):\n",
    "        return wkt / normalization\n",
    "    if normalization == 'empty' or normalization == True:\n",
    "        return wkt / nv\n",
    "    if normalization == 'complete':\n",
    "        if normalized_laplacian:\n",
    "            return wkt / (1 + (nv - 1) * np.cos(timescales))\n",
    "        else:\n",
    "            return wkt / (1 + (nv - 1) * np.cos(nv * timescales))\n",
    "    return wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetches dataset from graph kernel website\n",
    "def return_dataset(file_name):\n",
    "    #i = 'G_nci1'\n",
    "    dd = datasets.fetch_dataset(file_name,verbose = True)\n",
    "    graph_list = []\n",
    "    node_attr = []\n",
    "    for gg in dd.data:\n",
    "        v = set([i[0] for i in gg[0]]).union(set([i[1] for i in gg[0]]))\n",
    "        g_ = igraph.Graph()\n",
    "        g_.add_vertices([str(i) for i in v])\n",
    "        g_.add_edges([(str(i[0]), str(i[1])) for i in gg[0]])\n",
    "        g_.simplify()\n",
    "        A = g_.get_edgelist()\n",
    "        g = nx.Graph(A)\n",
    "        graph_list.append(g)\n",
    "        g_.vs['idx'] = [str(i) for i in g_.vs.indices]\n",
    "        node_attr.append(gg[1])\n",
    "    data_y = dd.target\n",
    "    return graph_list, data_y, node_attr\n",
    "def apply_netlsdwave(graphs,scale):\n",
    "    feature_matrix = []\n",
    "    for g in graphs:\n",
    "        feature_matrix.append(wave(g,scale))\n",
    "    return np.array(feature_matrix)\n",
    "def apply_netlsdheat(graphs,scale):\n",
    "    feature_matrix = []\n",
    "    for g in graphs:\n",
    "        feature_matrix.append(heat(g,scale))\n",
    "    return np.array(feature_matrix)\n",
    "def apply_RF(feature_matrix, labels):\n",
    "    model = RandomForestClassifier(n_estimators=10)\n",
    "    res = cross_val_score(model, feature_matrix, labels, cv=10, scoring='accuracy')\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPpWtyXWvE3y"
   },
   "source": [
    "#main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph successfuly loaded with 1000 number of nodes and 4912 number of edges\n",
      "total time: 0.35981321334838867\n",
      "graph successfuly loaded with 10000 number of nodes and 49762 number of edges\n",
      "total time: 75.65943145751953\n",
      "graph successfuly loaded with 4039 number of nodes and 88234 number of edges\n",
      "total time: 23.7445170879364\n",
      "graph successfuly loaded with 37702 number of nodes and 289004 number of edges\n",
      "total time: 210.3531322479248\n"
     ]
    }
   ],
   "source": [
    "file = open(\"algos_time_res.csv\",'a',newline = '')\n",
    "res_writer = csv.writer(file, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "data = ['ER1k', 'ER10k','facebook_g','github_g']\n",
    "scale = 250\n",
    "for d in data:\n",
    "    graph = nx.read_graphml('./'+d+'.gxl')\n",
    "    print(\"graph successfuly loaded with {} number of nodes and {} number of edges\".format(graph.number_of_nodes(), graph.number_of_edges()))\n",
    "    graph_list = [graph]\n",
    "    start = time.time()\n",
    "    sig = apply_netlsdheat(graph_list,scale)\n",
    "    end = time.time()\n",
    "    print(\"total time:\", end-start)\n",
    "    to_write = ['NetLSD',d,end-start]\n",
    "    res_writer.writerow(to_write)\n",
    "    file.flush()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph successfuly loaded with 4039 number of nodes and 88234 number of edges\n",
      "total time: 7.365434885025024\n"
     ]
    }
   ],
   "source": [
    "file = open(\"algos_time_res.csv\",'a',newline = '')\n",
    "res_writer = csv.writer(file, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "data = ['facebook_g']\n",
    "scale = 250\n",
    "for d in data:\n",
    "    graph = nx.read_graphml('./'+d+'.gxl')\n",
    "    print(\"graph successfuly loaded with {} number of nodes and {} number of edges\".format(graph.number_of_nodes(), graph.number_of_edges()))\n",
    "    graph_list = [graph]\n",
    "    start = time.time()\n",
    "    sig = apply_netlsdheat(graph_list,scale)\n",
    "    end = time.time()\n",
    "    print(\"total time:\", end-start)\n",
    "    to_write = ['NetLSD',d,end-start]\n",
    "    res_writer.writerow(to_write)\n",
    "    file.flush()\n",
    "    \n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NetLSD_nci1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
