{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-igraph in c:\\users\\rank arrow\\appdata\\roaming\\python\\python39\\site-packages (0.9.11)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\appl\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: igraph==0.9.11 in c:\\users\\rank arrow\\appdata\\roaming\\python\\python39\\site-packages (from python-igraph) (0.9.11)\n",
      "Requirement already satisfied: texttable>=1.6.2 in c:\\users\\rank arrow\\appdata\\roaming\\python\\python39\\site-packages (from igraph==0.9.11->python-igraph) (1.6.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-igraph --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Kristy'\n",
    "import time\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from igraph import  *\n",
    "import scipy as sc\n",
    "import networkx as nx\n",
    "import csv\n",
    "import time\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import sys,igraph\n",
    "import scipy.spatial.distance\n",
    "from math import sqrt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" find the egonet of each node in the given graph. Return value will be a dictionary {vertex_index: [list of neighbours]}\n",
    "    e.g.  {1:[0,2] , 2:[1,3]}\n",
    "\"\"\"\n",
    "def get_egonet (g):\n",
    "    egonet = {k.index: g.neighbors(k,mode=ALL) for k in g.vs};\n",
    "    return egonet;\n",
    "\n",
    "\"\"\" To find the degree of nodes in the given graph, Return value will be a dictionary {vertex_index : degree}\n",
    "    e.g. {1:2 , 2:2 }\n",
    "\"\"\"\n",
    "def get_di(g):\n",
    "    neighbor_size = {k.index : g.degree(k,mode=ALL) for k in g.vs};\n",
    "    return neighbor_size;\n",
    "\n",
    "\"\"\" To find the clustering index of the nodes in the given graph. Return value will be a dictionary {vertex_index: clustering_index}\n",
    "\"\"\"\n",
    "def get_ci(g):\n",
    "    clustering_index = {k.index : g.transitivity_local_undirected(vertices=k,mode=TRANSITIVITY_ZERO) for k in g.vs};\n",
    "    return clustering_index;\n",
    "\n",
    "\"\"\" To find the average number of two hop neighbors of all nodes in the given graph. Return value will be a dictionary {vertex_index: average_two_hop_neighbors}\n",
    "\"\"\"\n",
    "def get_dni(g):\n",
    "    two_hop_neighbors = {};\n",
    "    for key,value in get_egonet(g).items():\n",
    "        avg_hop = mean([g.degree(k,mode=ALL) for k in value]);\n",
    "        two_hop_neighbors[key] = avg_hop;\n",
    "    return two_hop_neighbors;\n",
    "\n",
    "\"\"\" To find the average clustering coefficient of all nodes in the given graph. Return value will be a dictionary {vertex_index: average_clustering coefficient}\n",
    "\"\"\"\n",
    "def get_cni(g):\n",
    "    avg_ci = {}\n",
    "    ci = get_ci(g)\n",
    "    for key,value in get_egonet(g).items():\n",
    "        temp = mean([ci[k] for k in value])\n",
    "        avg_ci[key] = temp\n",
    "    return avg_ci\n",
    "\n",
    "\"\"\" To find the number of edges in the egonet of each node in the given graph. Return value will be a dictionary {vertex_index: edges_in_egonet}\n",
    "\"\"\"\n",
    "def get_eegoi(g):\n",
    "    egonet = get_egonet(g);\n",
    "    eegoi = {};\n",
    "    for vertex in g.vs:\n",
    "        sg = g.subgraph(egonet[vertex.index] + [vertex.index]);\n",
    "        egonet_es = [(k.source,k.target) for k in sg.es]\n",
    "        eegoi[vertex.index] = len(egonet_es);\n",
    "    return eegoi;\n",
    "\n",
    "\"\"\" To find the number of edges going out from the egonet of each node in the given graph. Return value will be a dictionary {vertex_index: outgoing_edges_from_egonet}\n",
    "\"\"\"\n",
    "def get_eoegoi(g):\n",
    "    egonet = get_egonet(g);\n",
    "    eoegoi = {};\n",
    "    for vertex in g.vs:\n",
    "        total_vs = [vertex.index];\n",
    "        for k in egonet[vertex.index]:\n",
    "            total_vs = total_vs + egonet[k] + [k];\n",
    "        total_vs = list(set(total_vs));\n",
    "        sg = g.subgraph(total_vs);\n",
    "        total_es = [(k.source,k.target) for k in sg.es];\n",
    "        sg_egonet = g.subgraph(egonet[vertex.index] + [vertex.index]);\n",
    "        egonet_es = [(k.source,k.target) for k in sg_egonet.es];\n",
    "        eoegoi[vertex.index] = len(list(set(total_es) - set(egonet_es)));\n",
    "    return eoegoi;\n",
    "\n",
    "\"\"\" To find the number of neighbors of the egonet of each node in the given graph. Return value will be a dictionary {vertex_index: neighbors_of_egonet}\n",
    "\"\"\"\n",
    "def get_negoi(g):\n",
    "    egonet = get_egonet(g);\n",
    "    negoi = {};\n",
    "    for vertex in g.vs:\n",
    "        egonet_vs = [vertex.index] + egonet[vertex.index];\n",
    "        total_vs = [];\n",
    "        for k in egonet[vertex.index]:\n",
    "            total_vs = total_vs +egonet[k];\n",
    "        total_vs = list(set(total_vs));\n",
    "        total_vs = [i for i in total_vs if i not in egonet_vs];\n",
    "        negoi[vertex.index] = len(total_vs);\n",
    "    return negoi;\n",
    "\n",
    "\"\"\" extract the features of each node in the given graph. Return value will be list of tuples of all features of each node\n",
    "    e.g. if there are k nodes in graph then return value will be\n",
    "    [(di0,di0,dni0,cni0,eego0,eoego0,negoi0),(di1,di1,dni1,cni1,eego1,eoego1,negoi1) ... (dik-1,dik-1,dnik-1,cnik-1,eegok-1,eoegok-1,negoik-1)]\n",
    "\"\"\"\n",
    "def get_features(g):\n",
    "    di= get_di(g);\n",
    "    ci= get_ci(g);\n",
    "    dni= get_dni(g);\n",
    "    cni=get_cni(g);\n",
    "    eego=get_eegoi(g);\n",
    "    eoego=get_eoegoi(g);\n",
    "    negoi=get_negoi(g);\n",
    "    all_features = [(di[v.index],ci[v.index],dni[v.index],cni[v.index],eego[v.index],eoego[v.index],negoi[v.index]) for v in g.vs];\n",
    "\n",
    "    return all_features;\n",
    "\n",
    "\"\"\" Get the signature vector of the graph. Return value will be a list of 35 values\n",
    "    e.g [mn(f0),md(f0),std_dev(f0),skw(f0),krt(f0), ... mn(f6),md(f6),std_dev(f6),skw(f6),krt(f6)]\n",
    "\"\"\"\n",
    "def get_signature(g):\n",
    "    all_features = get_features(g)\n",
    "    num_nodes = len(all_features);\n",
    "    signature = [];\n",
    "    for k in range(0,7):\n",
    "        feat_agg = [all_features[i][k] for i in range(0,num_nodes)];\n",
    "        mn = mean(feat_agg);\n",
    "        md = median(feat_agg);\n",
    "        std_dev = np.std(feat_agg);\n",
    "        skw = stats.skew(feat_agg);\n",
    "        krt = stats.kurtosis(feat_agg);\n",
    "        signature = signature + [mn,md,std_dev,skw,krt];\n",
    "    del all_features;\n",
    "    return signature;\n",
    "\n",
    "\"\"\" find canberra distance between two signature vectors \"\"\"\n",
    "def get_canberra_distance(sign1,sign2):\n",
    "    return abs(scipy.spatial.distance.canberra(sign1, sign2));\n",
    "\n",
    "\"\"\" calculate threshold. two methods used. Method 1: median + 3 * range_mean, Method 2: mean + 3*sigma_c/sqrt(window size = 2)\"\"\"\n",
    "def calculate_threshold(distances):\n",
    "    n = 2\n",
    "    moving_range = [abs(distances[i] - distances[i+1]) for i in range(0,len(distances)-1)];\n",
    "    #range_mean = mean(moving_range);\n",
    "    range_mean = sum(moving_range)/(len(moving_range)-1);\n",
    "    med = median(distances)\n",
    "    UCL = med + 3*range_mean\n",
    "    \"\"\" threshold calculation method 2. uncomment the code below to find threshold by method2 \"\"\"\n",
    "    \"\"\"\n",
    "    dist_mean = mean(distances);\n",
    "    sigma_c = range_mean / 1.128;\n",
    "    UCL = dist_mean + (3 * (sigma_c/sqrt(n)));\n",
    "    \"\"\"\n",
    "    return UCL;\n",
    "\n",
    "\"\"\" determine anomalies on the basis of threshold\"\"\"\n",
    "def anomalies(distances,u_threshold):\n",
    "    anomalies = []\n",
    "    for i in xrange(0, len(distances)-1):\n",
    "        if distances[i] >= u_threshold and distances[i+1] >= u_threshold:\n",
    "            anomalies.append(i+1);\n",
    "    return anomalies;\n",
    "\n",
    "\n",
    "def plot_dist(dists, u_threshold,filename):\n",
    "    \"\"\"\n",
    "    Plot the (N-1) canberra distances comparing each graph with the previous\n",
    "    \"\"\"\n",
    "    figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(dists, \"-o\")\n",
    "    axhline(y=u_threshold, ls='-', c='r',\n",
    "            label='Threshold: $median + 3 * range mean = %0.2f$'%(u_threshold),\n",
    "            lw=2)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Anomaly Detection: \")\n",
    "    plt.xlabel(\"Time Series Graphs\")\n",
    "    plt.ylabel(\"Canberra Distance\")\n",
    "    savefig(join('graph', filename+\".png\"),bbox_inches='tight')\n",
    "\n",
    "\n",
    "\"\"\" This functions gives the dictionary of the text file as key and the graph object formed by igraph from the text file\n",
    "    E.g. {'248_autonomous.txt': <igraph.Graph object at 0x000000001230B7D6D8>, '251_autonomous.txt':\n",
    "    <igraph.Graph object at 0x000000001277D7C8>}\n",
    "\"\"\"\n",
    "def get_graphs(dir_path):\n",
    "    file_paths = {f: join(dir_path,f) for f in listdir(dir_path)}\n",
    "    graphs = {}\n",
    "    for file,path in file_paths.items():\n",
    "        try:\n",
    "            fi = open(path,'r')\n",
    "            v, e = fi.next().split()\n",
    "            e_list = [(int(line.split()[0]),int(line.split()[1])) for line in list(fi)]\n",
    "            g = Graph()\n",
    "            g.add_vertices(int(v))\n",
    "            g.add_edges(e_list)\n",
    "            graphs[file] = g\n",
    "        finally:\n",
    "            fi.close()\n",
    "    return graphs\n",
    "\n",
    "\n",
    "#fetches dataset from graph kernel website\n",
    "def return_dataset(file_name):\n",
    "    #i = 'G_nci1'\n",
    "    dd = datasets.fetch_dataset(file_name,verbose = True)\n",
    "    graph_list = []\n",
    "    node_attr = []\n",
    "    for gg in dd.data:\n",
    "        v = set([i[0] for i in gg[0]]).union(set([i[1] for i in gg[0]]))\n",
    "        g_ = igraph.Graph()\n",
    "        g_.add_vertices([str(i) for i in v])\n",
    "        g_.add_edges([(str(i[0]), str(i[1])) for i in gg[0]])\n",
    "        g_.simplify()\n",
    "        graph_list.append(g_)\n",
    "        g_.vs['idx'] = [str(i) for i in g_.vs.indices]\n",
    "        node_attr.append(gg[1])\n",
    "    data_y = dd.target\n",
    "    return graph_list, data_y, node_attr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_RF(feature_matrix, labels):\n",
    "    model = RandomForestClassifier(n_estimators=500)\n",
    "    res = cross_val_score(model, feature_matrix, labels, cv=10, scoring='accuracy')\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RANKAR~1\\AppData\\Local\\Temp/ipykernel_15280/1626732745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mres_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQUOTE_MINIMAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mgraph_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_nodes\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mreturn_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mgraph_signatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#         np.savetxt(file_name+\"_NETSIMILE.txt\", np.array(graph_signatures),  delimiter=\",\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RANKAR~1\\AppData\\Local\\Temp/ipykernel_15280/1447970378.py\u001b[0m in \u001b[0;36mreturn_dataset\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreturn_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m#i = 'G_nci1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0mdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mgraph_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0mnode_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    run the program like this: python Netsimile.py C:/Users/Kristy/PycharmProjects/Netsimile/input_files\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = [\"MUTAG\",\"PTC_MR\",\"PROTEINS_full\",\"NCI1\",\"NCI109\",\"DD\",\"COLLAB\",\"REDDIT-BINARY\",\"REDDIT-MULTI-5K\",\"IMDB-BINARY\",\"IMDB-MULTI\"]\n",
    "    data = [\"REDDIT-MULTI-12K\"]\n",
    "    file = open(\"NETSMILE_res.csv\",'a',newline = '')\n",
    "    res_writer = csv.writer(file, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for file_name in data:\n",
    "        graph_list, data_y, data_nodes  = return_dataset(file_name)\n",
    "        graph_signatures = [get_signature(k) for k in graph_list]\n",
    "#         np.savetxt(file_name+\"_NETSIMILE.txt\", np.array(graph_signatures),  delimiter=\",\")\n",
    "        acc = apply_RF(graph_signatures,data_y)\n",
    "        print(\"accuracy:\",acc)\n",
    "        to_write = [file_name,acc]\n",
    "        print(to_write)\n",
    "        res_writer.writerow(to_write)\n",
    "        file.flush()\n",
    "    file.close()     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.8296976089477539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Appl\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Appl\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 11.22480034828186\n",
      "total time: 215.12991333007812\n",
      "total time: 3341.8454020023346\n"
     ]
    }
   ],
   "source": [
    "file = open(\"algos_time_res.csv\",'a',newline = '')\n",
    "res_writer = csv.writer(file, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "data = ['ER1k', 'ER10k','facebook_g']\n",
    "for d in data:\n",
    "    graph = igraph.read('./'+d+'.gxl',format=\"graphml\")\n",
    "    print(\"graph successfuly loaded with {} number of nodes and {} number of edges\".format(graph.number_of_nodes(), graph.number_of_edges()))\n",
    "\n",
    "    start = time.time()\n",
    "    sig = get_signature(graph)\n",
    "    end = time.time()\n",
    "    print(\"total time:\", end-start)\n",
    "    to_write = ['NetSmile',d,end-start]\n",
    "    res_writer.writerow(to_write)\n",
    "    file.flush()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph successfuly loaded with 1000 number of nodes and 4912 number of edges\n",
      "total time: 0.3381931781768799\n",
      "graph successfuly loaded with 10000 number of nodes and 49762 number of edges\n",
      "total time: 3.9021222591400146\n",
      "graph successfuly loaded with 4039 number of nodes and 88234 number of edges\n",
      "total time: 82.93905067443848\n"
     ]
    }
   ],
   "source": [
    "file = open(\"algos_time_res.csv\",'a',newline = '')\n",
    "res_writer = csv.writer(file, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "data = ['ER1k', 'ER10k','facebook_g']\n",
    "for d in data:\n",
    "    graph = igraph.read('./'+d+'.gxl',format=\"graphml\")\n",
    "    graph2 = nx.read_graphml('./'+d+'.gxl')\n",
    "    print(\"graph successfuly loaded with {} number of nodes and {} number of edges\".format(graph2.number_of_nodes(), graph2.number_of_edges()))\n",
    "\n",
    "    start = time.time()\n",
    "    sig = get_signature(graph)\n",
    "    end = time.time()\n",
    "    print(\"total time:\", end-start)\n",
    "    to_write = ['NetSmile',d,end-start]\n",
    "    res_writer.writerow(to_write)\n",
    "    file.flush()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"algos_time_res.csv\",'a',newline = '')\n",
    "res_writer = csv.writer(file, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "data = ['twitter_g','github_g']\n",
    "for d in data:\n",
    "    graph = igraph.read('../graphs/'+d+'.gxl',format=\"graphml\")\n",
    "    \n",
    "    print(\"done\")\n",
    "    start = time.time()\n",
    "    sig = get_signature(graph)\n",
    "    end = time.time()\n",
    "    print(\"total time:\", end-start)\n",
    "    to_write = ['NetSmile',d,end-start]\n",
    "    res_writer.writerow(to_write)\n",
    "    file.flush()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 7\n"
     ]
    }
   ],
   "source": [
    "graph = igraph.Graph.Tree(8,2)\n",
    "print(graph.vcount(), graph.ecount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.75, 1.5, 0.82915619758885, 0.49338220021815865, -1.371900826446281, 0.0, 0.0, 0.0, 0.0, -3.0, 2.375, 2.5, 0.6548430685625714, -0.2735766875628648, -1.5867494959760038, 0.0, 0.0, 0.0, 0.0, -3.0, 1.75, 1.5, 0.82915619758885, 0.49338220021815865, -1.371900826446281, 2.375, 2.0, 0.8569568250501305, 0.3910423176326535, -0.4662743322770484, 2.0, 2.0, 0.8660254037844386, 1.1547005383792515, 1.0]\n"
     ]
    }
   ],
   "source": [
    "sig = get_signature(graph)\n",
    "print(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sig)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
